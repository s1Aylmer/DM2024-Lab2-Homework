{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:洪裕竣\n",
    "\n",
    "Student ID:s11214618@gm.cyut.edu.tw\n",
    "\n",
    "GitHub ID:sAylmer\n",
    "\n",
    "Kaggle name:\n",
    "\n",
    "Kaggle private scoreboard snapshot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 1 (Take home): **  \n",
    "# Answer here\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Step 1: Tokenize and preprocess the text\n",
    "def tokenize_text(text):\n",
    "    # Remove special characters and split words\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "# Apply tokenization to the train and test datasets\n",
    "train_words = train_df['text'].apply(tokenize_text).sum()\n",
    "test_words = test_df['text'].apply(tokenize_text).sum()\n",
    "\n",
    "# Step 2: Calculate word frequencies\n",
    "train_word_counts = Counter(train_words)\n",
    "test_word_counts = Counter(test_words)\n",
    "\n",
    "# Step 3: Get the top 30 words\n",
    "top_30_train = train_word_counts.most_common(30)\n",
    "top_30_test = test_word_counts.most_common(30)\n",
    "\n",
    "# Step 4: Prepare data for plotting\n",
    "train_words, train_counts = zip(*top_30_train)\n",
    "test_words, test_counts = zip(*top_30_test)\n",
    "\n",
    "# Step 5: Plot the word frequencies\n",
    "# Train dataset\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(train_words, train_counts, color='blue', alpha=0.7)\n",
    "plt.title('Top 30 Word Frequencies in Train Dataset')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test dataset\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(test_words, test_counts, color='green', alpha=0.7)\n",
    "plt.title('Top 30 Word Frequencies in Test Dataset')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 2 (Take home): ** \n",
    "\n",
    "# import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "# build TF-IDF vectorizer with some different parameters\n",
    "TFIDF_1000 = TfidfVectorizer(max_features=1000,\n",
    "                              tokenizer=nltk.word_tokenize,  # 使用 NLTK 的 tokenizer\n",
    "                              stop_words='english',  # 去除常見的英文停用詞\n",
    "                              ngram_range=(1, 2))  # 使用 unigram 和 bigram\n",
    "\n",
    "# apply TF-IDF to training data\n",
    "TFIDF_1000.fit(train_df['text'])\n",
    "\n",
    "# transform the training data to obtain the TF-IDF feature matrix\n",
    "train_data_TFIDF_features_1000 = TFIDF_1000.transform(train_df['text'])\n",
    "\n",
    "# check dimension\n",
    "print(train_data_TFIDF_features_1000.shape)\n",
    "\n",
    "# convert to array (optional)\n",
    "train_data_array = train_data_TFIDF_features_1000.toarray()\n",
    "\n",
    "# get feature names\n",
    "feature_names_1000 = TFIDF_1000.get_feature_names_out()\n",
    "\n",
    "# print specific feature names from 100 to 110\n",
    "print(feature_names_1000[100:110])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 3 (Take home): ** \n",
    "# Answer here\n",
    "#這是用來解釋情緒分類真實發生的表現次數作為混淆矩陣在某些訊息上顏色深度作為次數的辨識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 4 (Take home): **  \n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Load your dataset\n",
    "# Assuming we have a dataset of text samples and their labels called 'texts' and 'labels'\n",
    "texts = [\"Sample text 1\", \"Sample text 2\", \"Sample text 3\", \"Sample text 4\"]  # Replace with your actual text data\n",
    "labels = [\"anger\", \"fear\", \"joy\", \"sadness\"]  # Replace with your actual label data\n",
    "\n",
    "# Ensure there are enough samples to split properly\n",
    "if len(texts) < 2:\n",
    "    raise ValueError(\"Not enough data samples. Please provide at least 2 samples to perform train-test split.\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the text data into a TF-IDF representation\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # Using 1-2 n-grams to capture more context\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "# Build a Naive Bayes model and train it\n",
    "nb_model = MultinomialNB(alpha=0.5)  # Adjusting alpha for better smoothing\n",
    "nb_model.fit(X_train_counts, y_train)\n",
    "\n",
    "# Make predictions on the training and test sets\n",
    "y_train_pred = nb_model.predict(X_train_counts)\n",
    "y_test_pred = nb_model.predict(X_test_counts)\n",
    "\n",
    "# Calculate training and testing accuracy\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "print('Training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('Testing accuracy: {}'.format(round(acc_test, 2)))\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_true=y_test, y_pred=y_test_pred, zero_division=1))\n",
    "\n",
    "# Cross-validation to evaluate model robustness (adjust cv to be <= number of training samples and each class size)\n",
    "cv_folds = min(len(y_train), min(np.bincount([labels.index(label) for label in y_train])))  # Ensure number of folds does not exceed the number of unique labels or training samples or class sizes\n",
    "if cv_folds > 1:\n",
    "    scores = cross_val_score(nb_model, X_train_counts, y_train, cv=cv_folds)\n",
    "    print(f'Cross-validation scores: {scores}')\n",
    "    print(f'Mean accuracy: {scores.mean()}')\n",
    "else:\n",
    "    print(\"Not enough data for cross-validation.\")\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_test_pred, labels=[\"anger\", \"fear\", \"joy\", \"sadness\"])\n",
    "\n",
    "# Function for visualizing the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=sns.cubehelix_palette(as_cmap=True)):\n",
    "    \"\"\"\n",
    "    This function is modified from: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    tick_marks = np.arange(len(classes))    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes,\n",
    "           yticklabels=classes,\n",
    "           title=title,\n",
    "           xlabel='Predicted label',\n",
    "           ylabel='True label')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylim(len(classes) - 0.5, -0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
    "plot_confusion_matrix(cm, classes=my_tags, title='Confusion matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 5 (Take home): ** \n",
    "\n",
    "# Answer here\n",
    "#樸素貝葉斯-基於機率假設特徵之間相互獨立.適合處理高維度數據,計算速度快特別適合文字分.\n",
    "#決策樹-使用樹狀結構來做決策 不假設特徵獨立模型可解釋性強，但容易過度擬合尤其當樹很深時."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "** >>> Exercise 6 (Take home): **\n",
    "# Answer here\n",
    "\n",
    "#準確率曲線：\n",
    "#從圖中可以看到訓練準確率不斷提高\n",
    "#但驗證準確率可能停滯不前或甚至下降\n",
    "#這表明模型可能出現了過度擬合的現象\n",
    "#訓練集上的準確率很高\n",
    "#而驗證集上的準確率很低\n",
    "#在模型在訓練集上學習了太多的細節失去了對新資料的泛化能力.\n",
    "\n",
    "#損失曲線：\n",
    "#訓練損失不斷下降\n",
    "#但驗證損失在某些點後開始上升\n",
    "#進一步支持了模型可能過度擬合的結論\n",
    "#過度擬合時會讓驗證損失會逐漸增加,而訓練損失仍一直在減少.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 7 (Take home): **  \n",
    "\n",
    "# Answer here\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Sample dataset (replace with your actual text and labels)\n",
    "texts = [\"I love programming\", \"Python is amazing\", \"I hate bugs\", \"Debugging is tough\"]\n",
    "labels = [1, 1, 0, 0]  # 1 for positive, 0 for negative\n",
    "\n",
    "# Assuming `word2vec_model` is already trained or loaded\n",
    "# Convert sentences to sentence embeddings by averaging word vectors\n",
    "def sentence_to_vector(sentence, model):\n",
    "    words = sentence.split()  # Tokenize the sentence\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if not word_vectors:  # Handle empty sentences or words not in vocabulary\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)  # Mean pooling\n",
    "\n",
    "# Generate sentence embeddings for the dataset\n",
    "sentence_embeddings = np.array([sentence_to_vector(sentence, word2vec_model) for sentence in texts])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 8 (Take home): **  \n",
    "# Required Libraries\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `w2v_google_model` is already loaded and contains word embeddings\n",
    "\n",
    "#  1- Retrieve the 15 most similar words for each target word\n",
    "topn = 15\n",
    "words = [\"angry\", \"happy\", \"sad\", \"fear\"]\n",
    "\n",
    "word_groups = {word: [word] + [sim_word for sim_word, _ in w2v_google_model.most_similar(word, topn=topn)]\n",
    "               for word in words}\n",
    "\n",
    "# Flatten the list to create a single list of target words and their related words.\n",
    "all_words = sum(word_groups.values(), [])\n",
    "\n",
    "#  2-Extract embeddings for all selected words\n",
    "word_vectors = [w2v_google_model[word] for word in all_words]\n",
    "\n",
    "# Convert word_vectors to a NumPy array\n",
    "word_vectors_array = np.array(word_vectors)\n",
    "\n",
    "# 3-Apply t-SNE\n",
    "tsne = TSNE(n_components=2, metric='cosine', random_state=42)\n",
    "word_vectors_tsne = tsne.fit_transform(word_vectors_array)\n",
    "\n",
    "# 4-Apply UMAP\n",
    "umap_model = umap.UMAP(n_components=2, metric='cosine', random_state=42)\n",
    "word_vectors_umap = umap_model.fit_transform(word_vectors_array)\n",
    "\n",
    "# 5- Define the plot_embeddings function\n",
    "def plot_embeddings(embeddings, title, words, color_groups):\n",
    "    \"\"\"\n",
    "    Plot word embeddings using matplotlib.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, (x, y) in enumerate(embeddings):\n",
    "        plt.scatter(x, y, color=color_groups[i], label=words[i] if i % (topn + 1) == 0 else \"\")\n",
    "        plt.annotate(words[i],\n",
    "                     (x, y),\n",
    "                     textcoords=\"offset points\",\n",
    "                     xytext=(0, 5),\n",
    "                     ha='center',\n",
    "                     fontsize=8)\n",
    "    # Ensure unique labels in legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), loc=\"upper left\", fontsize=10)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Group colors\n",
    "colors = ['blue', 'green', 'red', 'orange']  # One for each target word group\n",
    "color_groups = [colors[i // (topn + 1)] for i in range(len(all_words))]\n",
    "\n",
    "# Plot t-SNE\n",
    "plot_embeddings(word_vectors_tsne, \"t-SNE Visualization\", all_words, color_groups)\n",
    "\n",
    "# Plot UMAP\n",
    "plot_embeddings(word_vectors_umap, \"UMAP Visualization\", all_words, color_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 9 (Take home): **  \n",
    "# Answer here\n",
    "import ollama\n",
    "response = ollama.chat(model='llama3.2', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is data mining? (in markdown format)'\n",
    "    },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 10 (Take home): **  \n",
    "# Answer here\n",
    "response3 = ollama.chat(model='llava-phi3', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is this image about?',\n",
    "        'images': ['C:/Users/User/DM2024-Lab2-Master-main/pics/example3.jpg'] #Image with the cat\n",
    "    },\n",
    "])\n",
    "\n",
    "display(Markdown(response3['message']['content']))\n",
    "#yes this Cat\n",
    "\n",
    "# Answer here\n",
    "response3 = ollama.chat(model='llava-phi3', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is this image about?',\n",
    "        'images': ['C:/Users/User/DM2024-Lab2-Master-main/pics/example4.jpg'] #Image with the cat\n",
    "    },\n",
    "])\n",
    "\n",
    "display(Markdown(response3['message']['content']))\n",
    "#yes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 11 (Take home): **  \n",
    "\n",
    "import ollama\n",
    "import bs4\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm_model = \"llama3.2\"  # Use your preferred model\n",
    "\n",
    "# Function to load, split, and retrieve documents from multiple URLs\n",
    "def load_and_retrieve_docs(urls):\n",
    "    docs = []\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    \n",
    "    for url in urls:\n",
    "        loader = WebBaseLoader(web_paths=(url,), bs_kwargs=dict())\n",
    "        url_docs = loader.load()  # Load content from each URL\n",
    "        splits = text_splitter.split_documents(url_docs)  # Split into chunks\n",
    "        docs.extend(splits)  # Add the split chunks to the document list\n",
    "    \n",
    "    embeddings = OllamaEmbeddings(model=llm_model)  # Generate embeddings\n",
    "    vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)  # Create vector database\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "# Function to format retrieved documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)  # Format the retrieved docs in an orderly manner\n",
    "\n",
    "# Function to generate answers using Ollama LLM\n",
    "def ollama_llm(question, context):\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response = ollama.chat(model='llama3.2', messages=[{'role': 'user', 'content': formatted_prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# RAG chain for retrieval and generation\n",
    "def rag_chain(question):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return ollama_llm(question, formatted_context)\n",
    "\n",
    "# URLs to retrieve information from\n",
    "urls = [\n",
    "    \"https://www.ibm.com/topics/large-language-models\",\n",
    "    \"https://www.microsoft.com/en-us/ai\",\n",
    "    \"https://openai.com/research\"\n",
    "]\n",
    "\n",
    "# Create the retriever for multiple sources\n",
    "retriever = load_and_retrieve_docs(urls)\n",
    "\n",
    "# Example prompts/questions\n",
    "questions = [\n",
    "    \"What are the related solutions of IBM with LLMs?\",\n",
    "    \"What AI services does Microsoft provide?\",\n",
    "    \"What is OpenAI's focus in research?\"\n",
    "]\n",
    "\n",
    "# Process questions and print answers\n",
    "for question in questions:\n",
    "    result = rag_chain(question)\n",
    "    print(f\"Question: {question}\\nAnswer: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 12 (Take home): **\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure history is available\n",
    "if 'history' in locals():\n",
    "    history_data = history.history\n",
    "else:\n",
    "    raise ValueError(\"Training history not found. Please ensure the model is trained before plotting.\")\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_data.get('accuracy', []), label='Training Accuracy')\n",
    "plt.plot(history_data.get('val_accuracy', []), label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_data.get('loss', []), label='Training Loss')\n",
    "plt.plot(history_data.get('val_loss', []), label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print comparison details\n",
    "print(\"KNN Results:\")\n",
    "try:\n",
    "    print(f\"KNN Accuracy: {accuracy:.2f}\")\n",
    "except NameError:\n",
    "    print(\"KNN Accuracy not available. Ensure the KNN accuracy variable is defined.\")\n",
    "\n",
    "print(\"\\nNeural Network Results:\")\n",
    "if 'accuracy' in history_data and 'val_accuracy' in history_data:\n",
    "    print(f\"Final Training Accuracy: {history_data['accuracy'][-1]:.2f}\")\n",
    "    print(f\"Final Validation Accuracy: {history_data['val_accuracy'][-1]:.2f}\")\n",
    "else:\n",
    "    print(\"Accuracy data not found in training history.\")\n",
    "\n",
    "# Discuss Results\n",
    "discussion = \"\"\"\n",
    "### Discussion:\n",
    "1. **KNN Observations**:\n",
    "   - KNN directly uses the LLM embeddings and computes nearest neighbors based on a distance metric.\n",
    "   - It is a non-parametric model and might struggle with high-dimensional embeddings due to the curse of dimensionality.\n",
    "\n",
    "2. **Neural Network Observations**:\n",
    "   - The NN benefits from learning feature interactions within the embeddings through backpropagation during training.\n",
    "   - However, overfitting is likely if the training dataset is small or lacks diversity, as observed from the validation gap.\n",
    "\n",
    "3. **Comparison**:\n",
    "   - Neural Networks often outperform KNN when the dataset size is sufficient due to their ability to model complex patterns in data.\n",
    "   - KNN may generalize better in noisy datasets or when the data points are highly representative of the entire input space.\n",
    "   - Embeddings from LLMs tend to work well for NNs as they can exploit latent features for classification.\n",
    "\n",
    "### Suggestions:\n",
    "1. Hyperparameter tuning for KNN (e.g., testing different `k` values) could improve its performance.\n",
    "2. Experiment with dropout layers, additional hidden layers, or different optimizers in the Neural Network to enhance generalization.\n",
    "3. Dimensionality reduction techniques like PCA could help improve KNN's performance in high-dimensional embedding spaces.\n",
    "\"\"\"\n",
    "print(discussion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ** >>> Exercise 13 (Take home): **\n",
    "# Answer here\n",
    "第一個：準確率 40%完全依賴模型的預訓練知識,適合快速原型,但性能有限\n",
    "第二個：準確率 47.5%提供每類一個範例明顯提升準確率,適合資料受限情境\n",
    "第三個：準確率更高,增加每個類有助模型捕捉細微差異,但可能需要更多數據\n",
    "\n",
    "少量範例能顯著提升性能,從零樣本到第一個樣本上改進最明顯,\n",
    "範例數增加有助於性能,但效益遞減,\n",
    "需要據任務上的條件需求跟資源限制的選擇適當的樣本量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
